{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02.2 Regression example: Sensor Fusion EDX + HAADF\n",
        "\n",
        "<br>"
      ],
      "id": "359d93b9-ac33-4ce2-a960-2054b6328396"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<h2>"
      ],
      "id": "1fe9151c-eac6-4244-82f7-a41ebdc7b8f3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Science in Electron Microscopy"
      ],
      "id": "55476d3b-e1d2-4db5-8ca2-60dd35fa59b1"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "</h2>"
      ],
      "id": "ad4eecb9-357e-47d5-bb6c-5e7cf6028469"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<hr>"
      ],
      "id": "ff59b423-617f-4efc-9ee5-18dc1232380a"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<h3>"
      ],
      "id": "11706c0b-6b16-4859-ae0c-42f746b35667"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Philipp Pelz"
      ],
      "id": "fd90114b-e704-459a-9807-5a74081b279e"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "</h3>"
      ],
      "id": "a0a81208-318e-46c9-a6fd-d38d1e9b113e"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<h3>"
      ],
      "id": "7f120c51-20b3-49c6-8e1d-97f7261abba1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2024"
      ],
      "id": "b8e44a9c-bfef-4ae5-99f3-228628e6ac8b"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "</h3>"
      ],
      "id": "f7908273-85eb-47de-9e29-64e0b317d799"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>"
      ],
      "id": "48832910-2efd-423a-9804-0d4668a4063e"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<h3>"
      ],
      "id": "cfadc723-2368-41f1-a0dc-a89a572a0c89"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Â  <https://github.com/ECLIPSE-Lab/WS24_DataScienceForEM>"
      ],
      "id": "a0a4c047-2482-46c8-85c1-62d543fbb698"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "</h3>"
      ],
      "id": "9cb9c730-dab8-4e9e-b1c0-f1ae2b02c6f4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Python modules\n",
        "\n",
        ":::"
      ],
      "id": "b36b1ed0-7836-4cd8-a9a2-db14ef18a21b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.sparse import spdiags\n",
        "import matplotlib.pyplot as plt\n",
        "import fusion_utils as utils\n",
        "from tqdm import tqdm \n",
        "import numpy as np\n",
        "import h5py\n",
        "# import sys\n",
        "# raise RuntimeError(sys.executable)"
      ],
      "id": "cell-2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Chemical Maps"
      ],
      "id": "8b2cf435-c88a-4a88-9565-8491974b245a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fname = 'CoSX_maps.h5'; mapNum = 'map7/'\n",
        "\n",
        "# Parse Chemical Maps\n",
        "elementList = ['Co', 'O', 'S']\n",
        "\n",
        "# Load Raw Data and Reshape\n",
        "file = h5py.File(fname, 'r')\n",
        "\n",
        "print('Available EDX Maps: ', list(file))\n",
        "\n",
        "xx = np.array([],dtype=np.float32)\n",
        "for ee in elementList:\n",
        "\n",
        "    # Read Chemical Map for Element \"ee\"\n",
        "    edsMap = file[mapNum+ee][:,:]\n",
        "\n",
        "    # Set Noise Floor to Zero and Normalize Chemical Maps\n",
        "    edsMap -= np.min(edsMap); edsMap /= np.max(edsMap)\n",
        "\n",
        "    # Concatenate Chemical Map to Variable of Interest\n",
        "    xx = np.concatenate([xx,edsMap.flatten()])\n",
        "\n",
        "# Make Copy of Raw Measurements for Poisson Maximum Likelihood Term \n",
        "xx0 = xx.copy()"
      ],
      "id": "cell-4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parse Meta Data, Prepare Reconstruction and Display Raw Chemical Maps"
      ],
      "id": "aa505d49-b10b-4587-8820-d86d0032aca2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image Dimensions\n",
        "(nx, ny) = edsMap.shape; nPix = nx * ny\n",
        "nz = len(elementList); lambdaHAADF = 1/nz\n",
        "\n",
        "import torch\n",
        "import kornia\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "class TVDenoise(torch.nn.Module):\n",
        "    def __init__(self, noisy_image, lambdaTV):\n",
        "        super(TVDenoise, self).__init__()\n",
        "        self.lambdaTV = lambdaTV\n",
        "        self.l2_term = torch.nn.MSELoss(reduction='mean')\n",
        "        self.regularization_term = kornia.losses.TotalVariation()\n",
        "        # create the variable which will be optimized to produce the noise free image\n",
        "        self.clean_image = torch.nn.Parameter(data=noisy_image.clone(), requires_grad=True)\n",
        "        self.noisy_image = noisy_image\n",
        "\n",
        "    def forward(self):\n",
        "        return self.l2_term(self.clean_image, self.noisy_image) + lambdaTV * self.regularization_term(self.clean_image)\n",
        "\n",
        "    def get_clean_image(self):\n",
        "        return self.clean_image\n",
        "\n",
        "def reg(x, lambda_TV, ng):\n",
        "  # read the image with OpenCV\n",
        "  img = x\n",
        "  # convert to torch tensor\n",
        "  noisy_image: torch.tensor = kornia.image_to_tensor(img).squeeze()  # CxHxW\n",
        "  # define the total variation denoising network\n",
        "  tv_denoiser = TVDenoise(noisy_image, lambda_TV)\n",
        "  # define the optimizer to optimize the 1 parameter of tv_denoiser\n",
        "  optimizer = torch.optim.SGD(tv_denoiser.parameters(), lr=0.1, momentum=0.9)\n",
        "  # run the optimization loop\n",
        "  for i in range(ng):\n",
        "      optimizer.zero_grad()\n",
        "      loss = tv_denoiser()\n",
        "      # if i % 25 == 0:\n",
        "      #     print(\"Loss in iteration {} of {}: {:.3f}\".format(i, ng, loss.item()))\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "  # convert back to numpy\n",
        "  img_clean: np.ndarray = kornia.tensor_to_image(tv_denoiser.get_clean_image())\n",
        "  return img_clean, loss.item()\n",
        "\n",
        "# HAADF Signal (Measurements)\n",
        "b = file[mapNum+'HAADF'][:].flatten()\n",
        "\n",
        "# Data Subtraction and Normalization \n",
        "b -= np.min(b); b /= np.max(b)\n",
        "\n",
        "# Create Summation Matrix\n",
        "A = utils.create_measurement_matrix(nx,ny,nz)\n"
      ],
      "id": "cell-6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show Raw Data\n",
        "utils.plot_elemental_images(xx, b, elementList, nx, ny, 2,2)"
      ],
      "id": "cell-7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Regularization"
      ],
      "id": "ee1c5cd9-576b-4986-895e-cc5be9ac388a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regularize = True; ng = 15; lambdaTV = 0.1; \n",
        "r, cost = reg(edsMap, lambdaTV, ng)\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(r)\n",
        "plt.show()"
      ],
      "id": "cell-9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform Multi-Modal Data Fusion"
      ],
      "id": "3a00ef42-961f-427e-bd16-46b0963a2ecb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convergence Parameters\n",
        "gamma = 1.6; lambdaEDS = 5e-6; nIter = 30; bkg = 1e-1\n",
        "\n",
        "# TV Min Parameters\n",
        "regularize = True; ng = 15; lambdaTV = 0.1; \n",
        "\n",
        "# Auxiliary Functions\n",
        "lsqFun = lambda inData : 0.5 * np.linalg.norm(A.dot(inData**gamma) - b) **2\n",
        "poissonFun = lambda inData : np.sum(xx0 * np.log(inData + 1e-8) - inData)\n",
        "\n",
        "# Main Loop\n",
        "costHAADF = np.zeros(nIter,dtype=np.float32); costEDS = np.zeros(nIter, dtype=np.float32); costTV = np.zeros(nIter, dtype=np.float32);\n",
        "for kk in tqdm(range(nIter)):\n",
        "\n",
        "    # HAADF Update\n",
        "    xx -=  gamma * spdiags(xx**(gamma - 1), [0], nz*nx*ny, nz*nx*ny) * lambdaHAADF * A.transpose() * (A.dot(xx**gamma) - b) \\\n",
        "            + lambdaEDS * (1 - xx0 / (xx + bkg))\n",
        "    xx[xx<0] = 0\n",
        "\n",
        "    # Regularization \n",
        "    if regularize:\n",
        "        for zz in range(nz):\n",
        "            w, cost = reg( xx[zz*nPix:(zz+1)*nPix].reshape(ny,nx), lambdaTV, ng)\n",
        "            xx[zz*nPix:(zz+1)*nPix] = w.reshape((nPix,))\n",
        "\n",
        "    # Measure Cost Function\n",
        "    costHAADF[kk] = lsqFun(xx); costEDS[kk] = poissonFun(xx)\n",
        "\n",
        "    # Measure Isotropic TV \n",
        "    if regularize:\n",
        "        for zz in range(nz):\n",
        "            w, cost = reg( xx[zz*nPix:(zz+1)*nPix].reshape(ny,nx), lambdaTV, ng)\n",
        "            costTV[kk] += cost \n"
      ],
      "id": "cell-11"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Show Reconstructed Signal"
      ],
      "id": "26261858-7d52-4141-b663-3d2e0defa5c7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "utils.plot_elemental_images(xx,A.dot(xx**gamma),elementList,nx,ny,2,2)"
      ],
      "id": "cell-13"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display Cost Functions and Descent Parameters"
      ],
      "id": "4d59d150-1b34-4dd5-849d-54fd5634d3e5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "utils.plot_convergence(costHAADF, lambdaHAADF, costEDS, lambdaEDS, costTV, lambdaTV)"
      ],
      "id": "cell-15"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  }
}